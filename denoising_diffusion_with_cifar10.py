# -*- coding: utf-8 -*-
"""Denoising Diffusion with CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y7r_GJZH6zQBQiV9oKpXj8HRa1_ltuyz

This Notebook was created by Vincenzo Pluchino and Philip Tamb√®.
"""

#!pip install denoising_diffusion_pytorch datasets     #original code 
import sys  
import torch  

from google.colab import drive                        #mount the Drive into Colab
drive.mount("/content/drive/", force_remount=True)
cod_dir = "/content/drive/My Drive/results"

!git clone https://github.com/PhilipTamb/denoising_diffusion_pytorch_replication_result   #get our modified code from github
sys.path.append("/content/denoising_diffusion_pytorch_replication_result")

#install dependencies
!pip install einops
!pip install ema_pytorch

# Load the dataset from the huggingface hub
!pip install datasets
from datasets import load_dataset
cifar10 = load_dataset('cifar10')
cifar10['train'][0]

# Save the images to a folder for convenience
!mkdir -p train_images
def save_im(x, i):
  x['img'].save(f'train_images/{i:05}.png')
_ = cifar10['train'].map(save_im, with_indices=True)

torch.cuda.is_available()  #check if  GPU is available

# create directorys for the results into GPU
!mkdir /content/results/
!mkdir /content/results/images
!mkdir /content/results/models
milestone = 0

#copy the saving files into GPU directory
!cp /content/drive/MyDrive/results/*.pt /content/results/models

# print saving model files
!ls /content/results/models

# get list of models files
import glob
import os 

models_list = []
for filename in glob.glob("/content/results/models/*.pt"): 
    nomefile = os.path.basename(filename)
    models_list.append(nomefile)
print(models_list)

# sorting list and get the last model saved
import re

def atoi(text):
    return int(text) if text.isdigit() else text

def natural_keys(text):
    return [ atoi(c) for c in re.split(r'(\d+)', text) ]

models_list.sort(key=natural_keys)
number = re.findall(r'\d+', models_list[-1])
milestone = int(number[0])
print(milestone)

from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer  #import class

# Create the U-net model
model = Unet(
    dim = 64,
    dim_mults = (1, 2, 4, 8),
).cuda()

# Rough parameter count:
sum([p.numel() for p in model.parameters()]) # About the same as the 35 million in the paper

# define parameters of Gaussian Diffusion Model
diffusion = GaussianDiffusion(
    model,                       # U-ned prior defined 
    image_size = 32,    
    timesteps = 1000,            # number of steps as in the paper
    beta_schedule = 'linear',    # TO follow paper
    loss_type = 'l2'             # l2 set the loss formula at MSE 
).cuda()

# specify the training parameters
trainer = Trainer(
    diffusion,                        # Gaussian Diffusion Model 
    'train_images',                   # Dataset directory prior created
    augment_horizontal_flip = True,   # Some augmentation as in paper since this is a small dataset
    train_batch_size = 128,           # following the size in the paper
    train_lr = 2e-4,                  # the same of the paper
    train_num_steps = 800000,         # number of steps in the paper, we never achive this steps with free Colab but we are optimistic! :)
    gradient_accumulate_every = 2,    # gradient accumulation steps
    ema_decay = 0.9999,               # same EMA decay of the paper
    save_and_sample_every= 3000,      # timestep after which we save 20 images and 1 model parameter files
    results_folder= cod_dir,          # the saving folder linked in our drive
    ema_update_every= 10,             # updating the ema model every 10 steps to save compute
    amp = True                        # turn on mixed precision
)
if milestone != 0:                    # if there are saving models files, it load the last one model
 print("load model")
 trainer.load(milestone)
                                      # start training function
trainer.train()

# copying training ganerated imagies inside GPU directory
!cp /content/drive/MyDrive/results/*.png /content/results/images

img_dir = '/content/results/images'
!ls /content/results/images

from PIL import Image
Image.open(img_dir + '/sample-0-6000.png')

Image.open(img_dir +'/sample-0-30000.png')

Image.open(img_dir +'/sample-0-54000.png')

Image.open(img_dir +'/sample-0-75000.png')

# compute the FID metric
!pip install Pillow==9.0.0
!pip install clean-fid
from cleanfid import fid

fdir2 = img_dir            # images folder
fid_score = fid.compute_fid(fdir2, dataset_name="cifar10", dataset_res=32, dataset_split="train")   # we set CIFAR10 dataset to compute the FID
print(fid_score)

# import code for compute Inception Score
!git clone https://github.com/kvpratama/gan_metrics.git

# delete model directory because create problems to compute Inception Score
import shutil
shutil.rmtree('/content/results/models')

!ls /content/results/models        #the directory must be inexistent

# Compute and print Iception Score
!python /content/gan_metrics/inception_score.py --dataroot "/content/results/"